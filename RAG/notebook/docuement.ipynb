{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464d13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a5a1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Krish Naik', 'date_created': '2025-01-01'}, page_content='this is the main text content I am using to create RAG')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "doc = Document(\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"pages\": 1,\n",
    "        \"author\": \"Krish Naik\",\n",
    "        \"date_created\": \"2025-01-01\"\n",
    "    },\n",
    "    page_content=\"this is the main text content I am using to create RAG\"\n",
    ")\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7b1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os. makedirs(\"../data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e132c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts = {\n",
    "    \"../data/text_files/finadapt_intro.txt\": \"\"\"\n",
    "FinAdapt – India’s First Agentic-AI Powered Financial Guidance System for Gig Workers\n",
    "\n",
    "FinAdapt is a next-generation financial empowerment platform designed exclusively for India’s rapidly growing gig economy. \n",
    "In a world where freelancers, delivery partners, cab drivers, creators, tutors, technicians, and part-time earners struggle \n",
    "with irregular income and zero traditional financial support, FinAdapt acts as a dedicated, intelligent financial mentor.\n",
    "\n",
    "Unlike typical budgeting apps that only track expenses, FinAdapt uses agentic AI––a system capable of autonomous reasoning, \n",
    "planning, and multi-step decision making––to understand the user’s income patterns, financial habits, and long-term goals. \n",
    "It then creates real-time, personalized strategies for savings, investments, expense management, loans, taxes, and \n",
    "overall financial health.\n",
    "\n",
    "FinAdapt is built on the belief that **gig workers deserve the same financial clarity, security, and opportunity as \n",
    "full-time employees**, even if their income is unstable.\n",
    "\n",
    "Key Capabilities of FinAdapt:\n",
    "- **Dynamic budgeting engine** that adapts automatically to fluctuating income levels every week\n",
    "- **AI-generated smart savings goals** for essentials, emergencies, and personal aspirations\n",
    "- **Cashflow forecasting** that predicts upcoming shortages or surplus using the user’s historical spending behavior\n",
    "- **Automated tax assistant** that calculates tax liability, eligible deductions, and compliance tasks for gig workers\n",
    "- **Intelligent expense categorization** using AI-based receipt reading and transaction analysis\n",
    "- **Personalized loan readiness score** to help gig workers understand eligibility and reduce financial risk\n",
    "- **Insurance guidance** that explains health, life, and accident coverage in extremely simple words\n",
    "- **Educational micro-modules** that teach users financial literacy in easy regional-language content\n",
    "- **Real-time agentic AI mentor** that can plan, prioritize, compare, calculate, and recommend financial decisions like a human advisor\n",
    "- **Goal-based financial planning** for buying a bike, phone, home, education, or starting a business\n",
    "\n",
    "Vision and Impact:\n",
    "FinAdapt aims to become the financial backbone of India’s 100+ million gig and informal workers. The platform is not \n",
    "just a tool—it is a safety net, a support system, and a long-term financial growth partner. By combining agentic AI with \n",
    "deep financial workflows, FinAdapt ensures that every gig worker gains access to structured financial planning without \n",
    "needing prior knowledge or stable monthly income.\n",
    "\n",
    "With FinAdapt, gig workers finally receive:\n",
    "- More control over cashflow\n",
    "- Better financial decisions\n",
    "- Reduced stress during low-income months\n",
    "- Improved long-term financial stability\n",
    "- A stronger path toward savings, investments, and creditworthiness\n",
    "\n",
    "FinAdapt isn’t just another fintech project—it is a mission to build financial confidence, bridge opportunity gaps, \n",
    "and bring financial dignity to millions of independent workers across the country.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "for filepath, content in sample_texts.items():\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81f1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parthnandwalkar/Desktop/RAG/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Documents:\n",
      "[Document(metadata={'source': '../data/text_files/finadapt_intro.txt'}, page_content='\\nFinAdapt – India’s First Agentic-AI Powered Financial Guidance System for Gig Workers\\n\\nFinAdapt is a next-generation financial empowerment platform designed exclusively for India’s rapidly growing gig economy. \\nIn a world where freelancers, delivery partners, cab drivers, creators, tutors, technicians, and part-time earners struggle \\nwith irregular income and zero traditional financial support, FinAdapt acts as a dedicated, intelligent financial mentor.\\n\\nUnlike typical budgeting apps that only track expenses, FinAdapt uses agentic AI––a system capable of autonomous reasoning, \\nplanning, and multi-step decision making––to understand the user’s income patterns, financial habits, and long-term goals. \\nIt then creates real-time, personalized strategies for savings, investments, expense management, loans, taxes, and \\noverall financial health.\\n\\nFinAdapt is built on the belief that **gig workers deserve the same financial clarity, security, and opportunity as \\nfull-time employees**, even if their income is unstable.\\n\\nKey Capabilities of FinAdapt:\\n- **Dynamic budgeting engine** that adapts automatically to fluctuating income levels every week\\n- **AI-generated smart savings goals** for essentials, emergencies, and personal aspirations\\n- **Cashflow forecasting** that predicts upcoming shortages or surplus using the user’s historical spending behavior\\n- **Automated tax assistant** that calculates tax liability, eligible deductions, and compliance tasks for gig workers\\n- **Intelligent expense categorization** using AI-based receipt reading and transaction analysis\\n- **Personalized loan readiness score** to help gig workers understand eligibility and reduce financial risk\\n- **Insurance guidance** that explains health, life, and accident coverage in extremely simple words\\n- **Educational micro-modules** that teach users financial literacy in easy regional-language content\\n- **Real-time agentic AI mentor** that can plan, prioritize, compare, calculate, and recommend financial decisions like a human advisor\\n- **Goal-based financial planning** for buying a bike, phone, home, education, or starting a business\\n\\nVision and Impact:\\nFinAdapt aims to become the financial backbone of India’s 100+ million gig and informal workers. The platform is not \\njust a tool—it is a safety net, a support system, and a long-term financial growth partner. By combining agentic AI with \\ndeep financial workflows, FinAdapt ensures that every gig worker gains access to structured financial planning without \\nneeding prior knowledge or stable monthly income.\\n\\nWith FinAdapt, gig workers finally receive:\\n- More control over cashflow\\n- Better financial decisions\\n- Reduced stress during low-income months\\n- Improved long-term financial stability\\n- A stronger path toward savings, investments, and creditworthiness\\n\\nFinAdapt isn’t just another fintech project—it is a mission to build financial confidence, bridge opportunity gaps, \\nand bring financial dignity to millions of independent workers across the country.\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"../data/text_files/finadapt_intro.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(\"Loaded Documents:\")\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425e8788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents:\n",
      "[Document(metadata={'source': '../data/text_files/finadapt_intro.txt'}, page_content='\\nFinAdapt – India’s First Agentic-AI Powered Financial Guidance System for Gig Workers\\n\\nFinAdapt is a next-generation financial empowerment platform designed exclusively for India’s rapidly growing gig economy. \\nIn a world where freelancers, delivery partners, cab drivers, creators, tutors, technicians, and part-time earners struggle \\nwith irregular income and zero traditional financial support, FinAdapt acts as a dedicated, intelligent financial mentor.\\n\\nUnlike typical budgeting apps that only track expenses, FinAdapt uses agentic AI––a system capable of autonomous reasoning, \\nplanning, and multi-step decision making––to understand the user’s income patterns, financial habits, and long-term goals. \\nIt then creates real-time, personalized strategies for savings, investments, expense management, loans, taxes, and \\noverall financial health.\\n\\nFinAdapt is built on the belief that **gig workers deserve the same financial clarity, security, and opportunity as \\nfull-time employees**, even if their income is unstable.\\n\\nKey Capabilities of FinAdapt:\\n- **Dynamic budgeting engine** that adapts automatically to fluctuating income levels every week\\n- **AI-generated smart savings goals** for essentials, emergencies, and personal aspirations\\n- **Cashflow forecasting** that predicts upcoming shortages or surplus using the user’s historical spending behavior\\n- **Automated tax assistant** that calculates tax liability, eligible deductions, and compliance tasks for gig workers\\n- **Intelligent expense categorization** using AI-based receipt reading and transaction analysis\\n- **Personalized loan readiness score** to help gig workers understand eligibility and reduce financial risk\\n- **Insurance guidance** that explains health, life, and accident coverage in extremely simple words\\n- **Educational micro-modules** that teach users financial literacy in easy regional-language content\\n- **Real-time agentic AI mentor** that can plan, prioritize, compare, calculate, and recommend financial decisions like a human advisor\\n- **Goal-based financial planning** for buying a bike, phone, home, education, or starting a business\\n\\nVision and Impact:\\nFinAdapt aims to become the financial backbone of India’s 100+ million gig and informal workers. The platform is not \\njust a tool—it is a safety net, a support system, and a long-term financial growth partner. By combining agentic AI with \\ndeep financial workflows, FinAdapt ensures that every gig worker gains access to structured financial planning without \\nneeding prior knowledge or stable monthly income.\\n\\nWith FinAdapt, gig workers finally receive:\\n- More control over cashflow\\n- Better financial decisions\\n- Reduced stress during low-income months\\n- Improved long-term financial stability\\n- A stronger path toward savings, investments, and creditworthiness\\n\\nFinAdapt isn’t just another fintech project—it is a mission to build financial confidence, bridge opportunity gaps, \\nand bring financial dignity to millions of independent workers across the country.\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# Load all text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",            # directory path\n",
    "    glob=\"**/*.txt\",                # pattern to match .txt files\n",
    "    loader_cls=TextLoader,          # loader to use for each file\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "\n",
    "print(\"Loaded documents:\")\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd15867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDF documents loaded: 18\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "import os\n",
    "\n",
    "# Choose one PDF loader\n",
    "pdf_loader_cls = PyMuPDFLoader  # or PyPDFLoader\n",
    "\n",
    "# Directory containing PDF files\n",
    "pdf_directory = \"../data/pdf\"\n",
    "\n",
    "# Ensure directory exists\n",
    "if not os.path.exists(pdf_directory):\n",
    "    os.makedirs(pdf_directory)\n",
    "\n",
    "# Load all PDFs\n",
    "documents = []\n",
    "\n",
    "for root, dirs, files in os.walk(pdf_directory):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".pdf\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            loader = pdf_loader_cls(file_path)\n",
    "            docs = loader.load()\n",
    "            documents.extend(docs)\n",
    "\n",
    "print(f\"Total PDF documents loaded: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae3bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bbedc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original documents: 18\n",
      "Chunked documents: 29\n",
      "\n",
      "Sample chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Content: # FinAdapt – Enhanced Platform Report (Expanded 4-Page Edition) \n",
      " \n",
      "**India’s Pioneering Agentic-AI Financial Guidance System for Gig & Informal Workers** \n",
      " \n",
      "*Empowering Unpredictable Incomes with Inte...\n",
      "Metadata: {'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/new.pdf', 'file_path': '../data/pdf/new.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Untitled document', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'chunk_index': 0, 'total_chunks': 3, 'chunk_type': 'text'}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Content: Unlike conventional budgeting apps that rely on rigid templates and user inputs, FinAdapt \n",
      "functions as an **autonomous decision-making ecosystem**. Leveraging advanced AI agents, it \n",
      "proactively: \n",
      " \n",
      "...\n",
      "Metadata: {'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/new.pdf', 'file_path': '../data/pdf/new.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Untitled document', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'chunk_index': 1, 'total_chunks': 3, 'chunk_type': 'text'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize the text splitter with better parameters for financial content\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,       # Reduced from 1500 to keep related content together\n",
    "    chunk_overlap=200,     # Increased overlap for better context\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\\\. )\", \" \", \"\"],  # Added lookbehind for sentence splitting\n",
    "    keep_separator=True,   # Keep separators in the text\n",
    "    length_function=len,   # Use character count\n",
    "    is_separator_regex=True  # Enable regex for separators\n",
    ")\n",
    "\n",
    "# Enhanced chunking with metadata preservation\n",
    "def chunk_documents(documents):\n",
    "    chunked_docs = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Preserve original metadata\n",
    "        metadata = getattr(doc, 'metadata', {}).copy()\n",
    "        \n",
    "        # Split the document\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        \n",
    "        # Add chunk-specific metadata\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Preserve original metadata\n",
    "            chunk.metadata.update(metadata)\n",
    "            \n",
    "            # Add chunk-specific metadata\n",
    "            chunk.metadata.update({\n",
    "                \"chunk_index\": i,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                \"chunk_type\": \"text\"  # Could be 'table', 'figure', etc. if you add that logic\n",
    "            })\n",
    "            \n",
    "            # Clean up the chunk content\n",
    "            chunk.page_content = chunk.page_content.strip()\n",
    "            \n",
    "            # Only add non-empty chunks\n",
    "            if chunk.page_content:\n",
    "                chunked_docs.append(chunk)\n",
    "    \n",
    "    return chunked_docs\n",
    "\n",
    "# Apply the chunking to your documents\n",
    "chunked_documents = chunk_documents(documents)\n",
    "\n",
    "print(f\"Original documents: {len(documents)}\")\n",
    "print(f\"Chunked documents: {len(chunked_documents)}\")\n",
    "\n",
    "# Verify chunk quality\n",
    "print(\"\\nSample chunks:\")\n",
    "for i, chunk in enumerate(chunked_documents[:2]):  # Show first 2 chunks\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(\"Content:\", chunk.page_content[:200] + \"...\" if len(chunk.page_content) > 200 else chunk.page_content)\n",
    "    print(\"Metadata:\", {k: v for k, v in chunk.metadata.items() if not k.startswith('_')})\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc55276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List, Optional, Union\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EmbeddingManager:\n",
    "    \"\"\"\n",
    "    Document embedding manager using SentenceTransformer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"all-MiniLM-L6-v2\",\n",
    "        device: Optional[str] = None,\n",
    "        cache_folder: Optional[Union[str, Path]] = None\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.cache_folder = str(cache_folder) if cache_folder else None\n",
    "        self.model = None\n",
    "        self.embedding_dimension = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self) -> None:\n",
    "        \"\"\"Load the SentenceTransformer model.\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(\n",
    "                self.model_name,\n",
    "                device=self.device,\n",
    "                cache_folder=self.cache_folder\n",
    "            )\n",
    "            self.embedding_dimension = self.model.get_sentence_embedding_dimension()\n",
    "            logger.info(f\"Model loaded. Embedding dimension: {self.embedding_dimension}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load model {self.model_name}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_embedding(self, text: str, normalize: bool = True) -> np.ndarray:\n",
    "        \"\"\"Generate embedding for a single text.\"\"\"\n",
    "        if not text:\n",
    "            return np.zeros(self.embedding_dimension, dtype=np.float32)\n",
    "        return self.model.encode(text, convert_to_numpy=True, normalize_embeddings=normalize)\n",
    "\n",
    "    def get_embeddings(self, texts: List[str], batch_size: int = 32, show_progress_bar: bool = True, normalize: bool = True) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for a list of texts.\"\"\"\n",
    "        if not texts:\n",
    "            return np.empty((0, self.embedding_dimension), dtype=np.float32)\n",
    "        return self.model.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=show_progress_bar,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=normalize\n",
    "        )\n",
    "    \n",
    "    def embed_query(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Wrapper for query embedding (used by RAGRetriever).\"\"\"\n",
    "        return self.get_embedding(text)\n",
    "\n",
    "    def get_embedding_dimension(self) -> int:\n",
    "        return self.embedding_dimension or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca4de31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from typing import List, Any\n",
    "\n",
    "class VectorStore:\n",
    "    \"\"\"\n",
    "    Manages document embeddings in a ChromaDB vector store\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"Add documents and their embeddings to the vector store\"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Documents and embeddings length mismatch\")\n",
    "\n",
    "        ids, metadatas, docs_text, embeddings_list = [], [], [], []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            metadata = dict(getattr(doc, 'metadata', {}))\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(getattr(doc, 'page_content', ''))\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            docs_text.append(getattr(doc, 'page_content', ''))\n",
    "            embeddings_list.append(embedding.tolist() if isinstance(embedding, np.ndarray) else embedding)\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=docs_text\n",
    "            )\n",
    "            print(f\"Added {len(documents)} documents. Total now: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search(self, query_embedding, top_k: int = 5):\n",
    "        \"\"\"Search the vector store using query embedding\"\"\"\n",
    "        try:\n",
    "            # Convert numpy array to list if needed\n",
    "            if hasattr(query_embedding, 'tolist'):\n",
    "                query_embedding = query_embedding.tolist()\n",
    "\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=top_k\n",
    "            )\n",
    "\n",
    "            # Format results\n",
    "            formatted_results = []\n",
    "            if results and 'metadatas' in results and 'documents' in results:\n",
    "                for meta, content in zip(results['metadatas'][0], results['documents'][0]):\n",
    "                    formatted_results.append({\n",
    "                        'content': content,\n",
    "                        'metadata': meta\n",
    "                    })\n",
    "\n",
    "            return formatted_results\n",
    "        except Exception as e:\n",
    "            print(f\"Search failed: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a82ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:__main__:Model loaded. Embedding dimension: 384\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 23 chunks.\n",
      "Shape of first embedding (example): (384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure chunked_documents is already created\n",
    "# chunked_documents = [Document(page_content=\"...\", metadata={...}), ...]\n",
    "\n",
    "# Prepare text content for embeddings\n",
    "texts = [doc.page_content for doc in chunked_documents]\n",
    "\n",
    "# --- FIX: create an instance of EmbeddingManager ---\n",
    "embedding_manager = EmbeddingManager(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embedding_manager.get_embeddings(texts)\n",
    "\n",
    "print(f\"Generated embeddings for {len(texts)} chunks.\")\n",
    "\n",
    "# Check example embedding\n",
    "if embeddings is not None and len(embeddings) > 0:\n",
    "    print(f\"Shape of first embedding (example): {embeddings[0].shape}\")\n",
    "else:\n",
    "    print(\"No embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c27e40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "import traceback\n",
    "\n",
    "class RAGRetriever:\n",
    "    \"\"\"Retrieve top documents from vector store given a query\"\"\"\n",
    "\n",
    "    def __init__(self, vector_store, embedding_manager):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5) -> List[Any]:\n",
    "        try:\n",
    "            query_embedding = self.embedding_manager.embed_query(query)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to generate query embedding: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            results = self.vector_store.search(query_embedding, top_k=top_k)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Vector store search failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7454ee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:__main__:Model loaded. Embedding dimension: 384\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: finadapt_docs\n",
      "Existing documents: 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 23 documents. Total now: 373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document 1 ---\n",
      "Content: - **Monitors Financial Health**: Provides continuous, non-intrusive oversight with gentle nudges \n",
      "via app notifications, voice assistants, or SMS. \n",
      " \n",
      "### FinAdapt’s Core Mission \n",
      " \n",
      "At its heart, FinAdapt is driven by a transformative ethos: \n",
      " \n",
      "> “To democratize financial clarity, stability, and long-term wealth-building opportunities, \n",
      "ensuring every gig worker in India enjoys the same fiscal empowerment as traditional salaried \n",
      "professionals.” \n",
      " \n",
      "This mission addresses a critical gap: Over 100 million gig workers in India contribute \n",
      "immensely to the economy but grapple with financial precarity. FinAdapt bridges this divide by \n",
      "turning chaos into clarity.\n",
      "Metadata: {'page': 0, 'format': 'PDF 1.4', 'doc_index': 2, 'source': '../data/pdf/new.pdf', 'keywords': '', 'creationDate': '', 'author': '', 'creationdate': '', 'title': 'Untitled document', 'creator': '', 'file_path': '../data/pdf/new.pdf', 'moddate': '', 'trapped': '', 'total_pages': 6, 'chunk_index': 2, 'modDate': '', 'subject': '', 'producer': 'Skia/PDF m144 Google Docs Renderer', 'content_length': 664}\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Document 2 ---\n",
      "Content: Aiming to onboard 10 million users, FinAdapt will underpin India's gig GDP (₹10 lakh crore+ \n",
      "annually). \n",
      " \n",
      " \n",
      "FinAdapt transcends fintech—it's a dignity engine for the unsung heroes of India's economy. In \n",
      "a world of flux, it provides the anchor.\n",
      "Metadata: {'moddate': '', 'creationdate': '', 'creationDate': '', 'doc_index': 28, 'content_length': 245, 'total_pages': 6, 'trapped': '', 'source': '../data/pdf/new.pdf', 'subject': '', 'title': 'Untitled document', 'modDate': '', 'chunk_index': 2, 'page': 5, 'format': 'PDF 1.4', 'file_path': '../data/pdf/new.pdf', 'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': '', 'author': '', 'keywords': ''}\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Document 3 ---\n",
      "Content: Aiming to onboard 10 million users, FinAdapt will underpin India's gig GDP (₹10 lakh crore+ \n",
      "annually). \n",
      " \n",
      " \n",
      "FinAdapt transcends fintech—it's a dignity engine for the unsung heroes of India's economy. In \n",
      "a world of flux, it provides the anchor.\n",
      "Metadata: {'chunk_index': 2, 'keywords': '', 'page': 5, 'total_pages': 6, 'creationdate': '', 'trapped': '', 'subject': '', 'format': 'PDF 1.4', 'producer': 'Skia/PDF m144 Google Docs Renderer', 'modDate': '', 'doc_index': 28, 'title': 'Untitled document', 'file_path': '../data/pdf/new.pdf', 'author': '', 'moddate': '', 'content_length': 245, 'creationDate': '', 'source': '../data/pdf/new.pdf', 'creator': ''}\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Document 4 ---\n",
      "Content: Aiming to onboard 10 million users, FinAdapt will underpin India's gig GDP (₹10 lakh crore+ \n",
      "annually). \n",
      " \n",
      " \n",
      "FinAdapt transcends fintech—it's a dignity engine for the unsung heroes of India's economy. In \n",
      "a world of flux, it provides the anchor.\n",
      "Metadata: {'trapped': '', 'creationdate': '', 'author': '', 'keywords': '', 'content_length': 245, 'creationDate': '', 'page': 5, 'moddate': '', 'title': 'Untitled document', 'file_path': '../data/pdf/new.pdf', 'producer': 'Skia/PDF m144 Google Docs Renderer', 'format': 'PDF 1.4', 'source': '../data/pdf/new.pdf', 'modDate': '', 'creator': '', 'doc_index': 28, 'total_pages': 6, 'chunk_index': 2, 'subject': ''}\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Document 5 ---\n",
      "Content: Aiming to onboard 10 million users, FinAdapt will underpin India's gig GDP (₹10 lakh crore+ \n",
      "annually). \n",
      " \n",
      " \n",
      "FinAdapt transcends fintech—it's a dignity engine for the unsung heroes of India's economy. In \n",
      "a world of flux, it provides the anchor.\n",
      "Metadata: {'format': 'PDF 1.4', 'author': '', 'chunk_index': 2, 'file_path': '../data/pdf/new.pdf', 'modDate': '', 'source': '../data/pdf/new.pdf', 'creationDate': '', 'title': 'Untitled document', 'producer': 'Skia/PDF m144 Google Docs Renderer', 'subject': '', 'total_pages': 6, 'trapped': '', 'creationdate': '', 'doc_index': 28, 'moddate': '', 'creator': '', 'page': 5, 'keywords': '', 'content_length': 245}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ Initialize embedding manager and vector store\n",
    "embedding_manager = EmbeddingManager(\"all-MiniLM-L6-v2\")\n",
    "vector_store = VectorStore(\"finadapt_docs\", \"../data/vector_store\")\n",
    "\n",
    "# 2️⃣ Prepare documents (must exist)\n",
    "# Example: chunked_documents = [{'page_content': \"text here\", 'metadata': {...}}, ...]\n",
    "document_contents = [doc.page_content for doc in chunked_documents]\n",
    "document_embeddings = embedding_manager.get_embeddings(document_contents)\n",
    "\n",
    "# 3️⃣ Add to vector store\n",
    "vector_store.add_documents(chunked_documents, document_embeddings)\n",
    "\n",
    "# 4️⃣ Initialize retriever\n",
    "document_retriever = RAGRetriever(vector_store, embedding_manager)\n",
    "\n",
    "# 5️⃣ Retrieve\n",
    "search_results = document_retriever.retrieve(\n",
    "    query=\"What is FinAdapt's core mission?\",\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "# 6️⃣ Display results\n",
    "for idx, doc in enumerate(search_results, 1):\n",
    "    print(f\"\\n--- Document {idx} ---\")\n",
    "    print(\"Content:\", doc['content'][:200] + \"...\" if len(doc['content']) > 200 else doc['content'])\n",
    "    print(\"Metadata:\", doc['metadata'])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2484ce",
   "metadata": {},
   "source": [
    "### Connetion with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23004eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5740650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Initialize Groq LLM\n",
    "# ---------------------------\n",
    "\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq   # if using LangChain wrapper\n",
    "\n",
    "groq_api_key = \"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\"   # never hardcode real keys\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama-3.3-70b-versatile\",   # valid model\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Simple RAG Function\n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Simple RAG Function (Updated)\n",
    "# ---------------------------\n",
    "\n",
    "def rag_simple(query, retriever, llm, top_k=5):\n",
    "    \"\"\"\n",
    "    Enhanced RAG function that provides detailed, explanatory answers.\n",
    "    Combines retrieved context with general knowledge for comprehensive responses.\n",
    "    \"\"\"\n",
    "    # 1️⃣ Expand query for better retrieval\n",
    "    expanded_queries = [query]\n",
    "    if any(term in query.lower() for term in [\"expense\", \"categorization\", \"financial\", \"feature\", \"how\", \"what\", \"explain\"]):\n",
    "        expanded_queries.extend([\n",
    "            f\"Detailed explanation of {query}\",\n",
    "            f\"How FinAdapt implements {query}\",\n",
    "            f\"Technical details about {query} in FinAdapt\"\n",
    "        ])\n",
    "\n",
    "    # 2️⃣ Retrieve documents with expanded queries\n",
    "    all_results = []\n",
    "    for q in expanded_queries:\n",
    "        try:\n",
    "            results = retriever.retrieve(q, top_k=top_k)\n",
    "            all_results.extend([r for r in results if r not in all_results])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # 3️⃣ Build context with source tracking\n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(all_results[:top_k], 1):\n",
    "        content = doc.get('content', '').strip()\n",
    "        if content:\n",
    "            context_parts.append(f\"--- Source {i} ---\\n{content}\\n\")\n",
    "\n",
    "    context = \"\\n\".join(context_parts) if context_parts else \"No specific context found.\"\n",
    "\n",
    "    # 4️⃣ Enhanced prompt for explanatory responses\n",
    "    prompt = f\"\"\"You are a knowledgeable financial technology expert explaining FinAdapt's features.\n",
    "\n",
    "Context from documentation:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Please provide a detailed, informative response that:\n",
    "1. Directly answers the question based on the context\n",
    "2. If context is limited, supplement with general industry knowledge\n",
    "3. Explain how the feature works and its benefits\n",
    "4. Provide examples or use cases where applicable\n",
    "5. Keep the explanation clear and professional\n",
    "\n",
    "Structure your response with:\n",
    "- A clear opening statement\n",
    "- Key points in bullet format\n",
    "- A brief conclusion\n",
    "\n",
    "Detailed response:\"\"\"\n",
    "\n",
    "    # 5️⃣ Generate and process the response\n",
    "    try:\n",
    "        response = llm.invoke(input=prompt)\n",
    "        answer = response.content if hasattr(response, 'content') else str(response)\n",
    "        \n",
    "        # 6️⃣ Ensure the response is sufficiently detailed\n",
    "        if len(answer.split()) < 50:  # If response is too short\n",
    "            answer = f\"\"\"{answer}\n",
    "\n",
    "            Let me elaborate further. In financial technology platforms like FinAdapt, {query.lower().replace('?', '')} typically involves:\n",
    "\n",
    "            - Advanced algorithms that analyze transaction patterns\n",
    "            - Machine learning models that improve over time\n",
    "            - User-friendly interfaces for easy management\n",
    "            - Integration with banking and payment systems\n",
    "\n",
    "            This comprehensive approach ensures users get maximum value from the platform's features.\"\"\"\n",
    "        \n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fallback with general knowledge\n",
    "        return f\"\"\"I'll provide a detailed explanation based on general knowledge of financial platforms:\n",
    "\n",
    "        Regarding {query}, modern financial platforms like FinAdapt typically offer:\n",
    "\n",
    "        - Intelligent systems that automatically categorize transactions\n",
    "        - Machine learning algorithms that learn from user behavior\n",
    "        - Customizable categories and rules for personalization\n",
    "        - Detailed reporting and analytics\n",
    "\n",
    "        These features help users:\n",
    "        - Better understand their spending habits\n",
    "        - Save time on financial management\n",
    "        - Make more informed financial decisions\n",
    "        - Achieve their financial goals more effectively\n",
    "\n",
    "        While I don't have the specific implementation details for FinAdapt, this reflects industry standards for such features in leading financial platforms.\"\"\"\n",
    "\n",
    "# Example usage:\n",
    "# answer = rag_simple(\"How does expense categorization work in FinAdapt?\", document_retriever, llm)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9224bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s]\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinAdapt is a cutting-edge financial technology solution designed to cater to the unique needs of gig workers, freelancers, and micro-entrepreneurs with irregular income streams. While the provided context does not explicitly mention intelligent expense categorization, it highlights FinAdapt's autonomous decision-making ecosystem, which suggests the presence of advanced features like intelligent expense categorization. Based on general industry knowledge and the context provided, here are the key points to consider:\n",
      "\n",
      "* FinAdapt's autonomous decision-making ecosystem implies the use of advanced AI agents to proactively manage finances, which may include intelligent expense categorization.\n",
      "* Intelligent expense categorization is a feature that uses machine learning algorithms to automatically categorize transactions into relevant categories, such as food, transportation, or entertainment.\n",
      "* This feature works by analyzing transaction data, including merchant names, transaction amounts, and frequencies, to assign categories accurately.\n",
      "* The benefits of intelligent expense categorization include:\n",
      "  + Simplified expense tracking and management\n",
      "  + Improved budgeting and forecasting\n",
      "  + Enhanced financial insights and decision-making\n",
      "  + Reduced manual effort and increased accuracy\n",
      "* Examples of intelligent expense categorization in action include:\n",
      "  + Automatically categorizing a transaction at a coffee shop as \"food and beverage\"\n",
      "  + Identifying and categorizing recurring subscription payments, such as streaming services or software subscriptions\n",
      "  + Recognizing and categorizing transactions related to transportation, such as fuel purchases or ride-hailing services\n",
      "\n",
      "In conclusion, while the provided context does not directly confirm the presence of intelligent expense categorization in FinAdapt, its autonomous decision-making ecosystem and use of advanced AI agents suggest that this feature is likely available. Intelligent expense categorization is a valuable tool for individuals with irregular income streams, as it simplifies expense management, improves budgeting, and provides actionable financial insights.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\n",
    "    \"Does FinAdapt have intelligent expense categorization?\",\n",
    "    document_retriever,  # Your retriever instance\n",
    "    llm,\n",
    "    top_k=5\n",
    ")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
